---
title: "Q2_DecisionTreeAndRandomForest"
author: "Isabeau Lewis and Sam Boots"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Question 2 Analysis: Investigating differential responses to dessication in four populations of _Drosophila mojavensis_ by analyzing changes in cuticular hydrocarbon (CHC) composition.

To determine which cuticular hydrocarbon changes predict dessication, we will create a decision tree. This will allow us to determine which CHCs are involved in the dessication response in _D. mojavensis_.

We will analyze our data by performing a principal component analysis and then plotting the most influential components, relative to the three mentioned variables. This will allow us to conclude whether the selected variables yield differential responses and which variables displayed more significant separation of the CHC content values.

## Setup

Loading libraries:
```{r}
library(dplyr)
library(pROC)
library(e1071)
library(tree)
library(rpart)
library(gbm)
library(randomForest)
library(ggplot2)
library(tibble)
library(ggpubr)
```

Loading theme:
```{r}
library(cowplot)
theme_set(theme_cowplot(12))
```


## Loading the data
```{r}
CHC_dat<-read.csv("./data/CHC_dat.csv")
```

## Inspecting the data
```{r}
names(CHC_dat)
```

There are a lot of extra columns in the original data file that need to be removed (everything after "TOTAL")

```{r}
CHC_dat <- CHC_dat[1:37]
names(CHC_dat)
```
```{r}
str(CHC_dat)
```

Sample, pop, sex, cactus, and exposure should all be set to factors, and C.37.br.alkene should be set to numeric:
```{r}
CHC_dat <- CHC_dat %>% 
  mutate(SAMPLE = as.factor(SAMPLE),
         pop = as.factor(pop),
         sex = as.factor(sex),
         cactus = as.factor(cactus),
         exposure = as.factor(exposure),
         C.37.br.alkene = as.numeric(C.37.br.alkene)) #edit by Sam; CHC content changed from character to numeric
```

Checking the updated structure:
```{r}
str(CHC_dat) #everything here looks good
```

```{r}
head(CHC_dat)
```

```{r}
tail(CHC_dat)
```

Seeing if there are NAs:

```{r}
# Seeing which columns have missing values
CHC_dat %>%
  select_if(function(x) any(is.na(x))) %>%
  names() 
```

There was a single missing value, represented by a period, that was coerced into an NA when the column was converted from character to numeric.

Removing row containing NA value:

```{r}
CHC_dat<-CHC_dat[complete.cases(CHC_dat),]
```

## Dimensions of the data frame
```{r}
dim(CHC_dat)
```

The final dimensions are 115 rows and 37 columns.


## Splitting the data into a training and a test dataset
```{r}
Rows<-c(1:nrow(CHC_dat))
Train<-Rows %% 2==1
Validate<-Rows %% 2==0

dat_train<-CHC_dat[Train,]
dat_validate<-CHC_dat[Validate,]

head(dat_train)
head(dat_validate)
```


## Decision tree

### Tree diagram with text

Getting only response and predictor variables:
```{r}
names(dat_train)
```

* This has Sample, pop, sex, cactus, and exposure, we want only exposure

```{r}
# Selecting only response and predictor variables:
dat_train_r <- dplyr::select(dat_train, -c("SAMPLE":"cactus"))
head(dat_train_r)
```

Creating the tree:
```{r}
DryTree<-tree(exposure~., data=dat_train_r)
plot(DryTree)
text(DryTree, cex=0.7, adj=0)
```

> A decision tree of the CHC features involved in response to different levels of dessication. Outcomes are printed along the bottom of the tree, coming from 'roots' and nodes listing each CHC feature & its corresponding value for decision-making.


### CHC feature most influential for classifying samples
The protein feature that was most influential for classifying samples was C.34. (at the top of the tree).

### Using predict() to provide the confusion matrix
```{r}
# Selecting only response and predictor variables:
dat_validate_r <- dplyr::select(dat_validate, -c("SAMPLE":"cactus"))

CatDat<-data.frame(Obs=dat_validate_r$exposure, Pred=predict(DryTree, dat_validate_r, type="class"))
table(CatDat)
```

## 4. Finding the misclassification error rate
```{r}
MisClass<-CatDat %>%
  filter(Obs!=Pred)
```


```{r}
nrow(MisClass)/nrow(CatDat)
```

The misclassification error rate was ~60%. This is a high error rate.

## Random Forest

Running randomforest function on training dataset, excluding rows with NA values:

```{r}
noNA<-complete.cases(dat_train_r)
dat_train_final<-dat_train_r[noNA,]
DryFor<-randomForest(exposure ~ ., data=dat_train_final, ntree=100, mtry=3, nodesize=5, importance=TRUE)
DryFor
```
Getting classifications Using predict():

```{r}
PredFor<-predict(DryFor, dat_validate_r, type="class")
head(DryFor)
```

Getting confusion matrix:
```{r}
CatDat2<-data.frame(Obs=dat_validate_r$exposure, Pred=predict(DryFor, dat_validate_r, type="class"))
table(CatDat2)
```

Getting the misclassification error rate:
```{r}
MisClass2<-CatDat2 %>%
  filter(Obs!=Pred)
nrow(MisClass2)/nrow(CatDat2)
```

The misclassification rate has dropped from ~60% to ~42% by using random forests.

### Plotting
```{r}

dry_imp<-as.data.frame(DryFor$importance)
dry_imp<-rownames_to_column(dry_imp, "CHC")
dry_imp<-dry_imp


d_imp <- ggplot(data=dry_imp, aes(x=reorder(CHC, MeanDecreaseAccuracy), y=MeanDecreaseAccuracy)) +
  geom_col() +
  xlab("CHC") +
  ylab("Importance")
ggpar(d_imp, x.text.angle=45)
```

> The relative importance of different CHC features in response to different levels of dessication
